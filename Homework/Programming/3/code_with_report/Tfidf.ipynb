{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3n4dgtrkkhTt",
        "outputId": "6b13c844-547d-4788-e47a-0b10ca35a228"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425345 sha256=7a4f1bcf47486a301ab245d02f60c3ed656d771e433adcecf77b8ef2d0b9f67b\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").appName(\"TF-IDF\").getOrCreate()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sc = spark.sparkContext\n",
        "rdd = sc.textFile(\"news.txt\")\n"
      ],
      "metadata": {
        "id": "LbBzlugykqYy"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_with_index = rdd.zipWithIndex()\n",
        "\n",
        "tf_with_doc_index = docs_with_index.flatMap(lambda doc: [((word, doc[1]), 1) for word in tokenize(doc[0])])\\\n",
        "                                   .reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "df = docs_with_index.flatMap(lambda doc: set(tokenize(doc[0])))\\\n",
        "                    .map(lambda word: (word, 1))\\\n",
        "                    .reduceByKey(lambda a, b: a + b)\n",
        "\n",
        "total_documents = docs_with_index.count()\n",
        "idf = df.map(lambda x: (x[0], math.log10(total_documents / x[1])))\n",
        "\n",
        "tf_idf = tf_with_doc_index.map(lambda x: (x[0][0], (x[0][1], x[1])))\\\n",
        "                          .join(idf)\\\n",
        "                          .map(lambda x: (x[0], (x[1][0][0], x[1][0][1] * x[1][1])))\\\n",
        "                          .groupByKey()\\\n",
        "                          .mapValues(list)\n"
      ],
      "metadata": {
        "id": "mX9q83YQmnts"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_related_documents(word, top_n=3):\n",
        "    return (tf_idf.filter(lambda x: x[0] == word)\n",
        "                  .flatMap(lambda x: [(doc_id, tfidf) for doc_id, tfidf in x[1]])\n",
        "                  .takeOrdered(top_n, key=lambda x: -x[1]))\n",
        "\n",
        "related_documents_japan = find_related_documents(\"japan\")\n",
        "related_documents_gas = find_related_documents(\"gas\")\n",
        "related_documents_market = find_related_documents(\"market\")\n",
        "\n",
        "print(\"Related documents for 'japan':\", related_documents_japan)\n",
        "print(\"Related documents for 'gas':\", related_documents_gas)\n",
        "print(\"Related documents for 'market':\", related_documents_market)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M53ff7VrmplQ",
        "outputId": "d884f71b-a97b-4004-c906-1becf54e49d9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Related documents for 'japan': [(6, 4.294091292476962), (5, 1.4313637641589874), (0, 0.9542425094393249)]\n",
            "Related documents for 'gas': [(0, 1.5563025007672873), (4, 0.7781512503836436)]\n",
            "Related documents for 'market': [(6, 1.4313637641589874), (7, 0.9542425094393249), (11, 0.9542425094393249)]\n"
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZyTSVXzZ6gx9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_and_convert_to_float32(filename):\n",
        "    data = np.load(filename)\n",
        "    return data.astype(np.float32)\n",
        "\n",
        "\n",
        "test_x = load_and_convert_to_float32('test_x.npy')\n",
        "test_y = load_and_convert_to_float32('test_y.npy')\n",
        "train_x = load_and_convert_to_float32('train_x.npy')\n",
        "train_y = load_and_convert_to_float32('train_y.npy')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "input_size = train_x.shape[1]\n",
        "\n",
        "num_classes = len(np.unique(train_y))\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Linear(input_size, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Linear(256, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.output_layer = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.output_layer(x)\n",
        "        return x\n",
        "\n",
        "model = NeuralNetwork(input_size=input_size, num_classes=num_classes)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n"
      ],
      "metadata": {
        "id": "X6QpRhkZ97iu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "train_x_tensor = torch.tensor(train_x).float()\n",
        "train_y_tensor = torch.tensor(train_y).long()\n",
        "test_x_tensor = torch.tensor(test_x).float()\n",
        "test_y_tensor = torch.tensor(test_y).long()\n",
        "\n",
        "train_dataset = TensorDataset(train_x_tensor, train_y_tensor)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "test_dataset = TensorDataset(test_x_tensor, test_y_tensor)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=64)\n",
        "\n",
        "\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "model.eval()\n",
        "total = 0\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f'Accuracy: {accuracy * 100}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpvBNkKIA0qS",
        "outputId": "05405603-dfa5-4029-a992-76f430aaffe5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 82.06%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.autograd.profiler as profiler\n",
        "\n",
        "test_x_tensor = torch.tensor(test_x).float()\n",
        "test_y_tensor = torch.tensor(test_y).long()\n",
        "test_dataset = TensorDataset(test_x_tensor, test_y_tensor)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=64)\n",
        "\n",
        "num_batches_to_profile = 100\n",
        "\n",
        "with profiler.profile(record_shapes=True, profile_memory=True, use_cuda=torch.cuda.is_available()) as prof:\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(test_loader):\n",
        "            if i >= num_batches_to_profile:\n",
        "                break\n",
        "            outputs = model(inputs)\n",
        "\n",
        "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWghsmpfDf6-",
        "outputId": "c35ff137-6fb3-46fe-8d36-25f189903e41"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        22.40%      59.753ms        45.99%     122.678ms       1.215ms      12.67 Mb           0 b           101  \n",
            "                                           aten::linear         0.73%       1.934ms        42.56%     113.505ms     283.762us      22.36 Mb      42.00 Kb           400  \n",
            "                                            aten::addmm        37.01%      98.708ms        40.65%     108.428ms     271.070us      22.36 Mb      22.36 Mb           400  \n",
            "                                            aten::stack         4.34%      11.568ms        12.01%      32.030ms     158.564us      12.67 Mb           0 b           202  \n",
            "                                           aten::select        11.50%      30.685ms        11.58%      30.895ms       2.390us           0 b           0 b         12928  \n",
            "                                       aten::batch_norm         0.30%     801.000us         7.62%      20.315ms      67.717us      21.88 Mb     -96.00 Kb           300  \n",
            "                           aten::_batch_norm_impl_index         0.85%       2.261ms         7.29%      19.450ms      64.833us      21.88 Mb     157.00 Kb           300  \n",
            "                                aten::native_batch_norm         5.40%      14.412ms         6.28%      16.739ms      55.797us      21.88 Mb    -839.50 Kb           300  \n",
            "                                              aten::cat         4.89%      13.044ms         4.89%      13.044ms      64.574us      12.67 Mb      12.67 Mb           202  \n",
            "                                             aten::relu         0.33%     884.000us         3.72%       9.919ms      33.063us      21.88 Mb     256.00 Kb           300  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 266.721ms\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.autograd.profiler as profiler\n",
        "import numpy as np\n",
        "\n",
        "train_x_tensor = torch.tensor(train_x).float()\n",
        "train_y_tensor = torch.tensor(train_y).long()\n",
        "test_x_tensor = torch.tensor(test_x).float()\n",
        "test_y_tensor = torch.tensor(test_y).long()\n",
        "\n",
        "train_dataset = TensorDataset(train_x_tensor, train_y_tensor)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "test_dataset = TensorDataset(test_x_tensor, test_y_tensor)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=64)\n",
        "\n",
        "class NeuralNetworkReLU(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(NeuralNetworkReLU, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_size, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "class NeuralNetworkTanh(NeuralNetworkReLU):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(NeuralNetworkTanh, self).__init__(input_size, num_classes)\n",
        "        self.layers[2] = nn.Tanh()\n",
        "        self.layers[5] = nn.Tanh()\n",
        "        self.layers[8] = nn.Tanh()\n",
        "\n",
        "class NeuralNetworkSigmoid(NeuralNetworkReLU):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(NeuralNetworkSigmoid, self).__init__(input_size, num_classes)\n",
        "        self.layers[2] = nn.Sigmoid()\n",
        "        self.layers[5] = nn.Sigmoid()\n",
        "        self.layers[8] = nn.Sigmoid()\n",
        "\n",
        "class NeuralNetworkGeLU(NeuralNetworkReLU):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(NeuralNetworkGeLU, self).__init__(input_size, num_classes)\n",
        "        self.layers[2] = nn.GELU()\n",
        "        self.layers[5] = nn.GELU()\n",
        "        self.layers[8] = nn.GELU()\n",
        "\n",
        "\n",
        "input_size = train_x.shape[1]\n",
        "num_classes = len(np.unique(train_y))\n",
        "\n",
        "model_relu = NeuralNetworkReLU(input_size, num_classes)\n",
        "model_tanh = NeuralNetworkTanh(input_size, num_classes)\n",
        "model_sigmoid = NeuralNetworkSigmoid(input_size, num_classes)\n",
        "model_gelu = NeuralNetworkGeLU(input_size, num_classes)\n",
        "\n",
        "models = {'ReLU': model_relu, 'Tanh': model_tanh, 'Sigmoid': model_sigmoid, 'GeLU': model_gelu}\n",
        "\n",
        "for activation_function, model in models.items():\n",
        "    with profiler.profile(record_shapes=True, profile_memory=True, use_cuda=torch.cuda.is_available()) as prof:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, (inputs, _) in enumerate(test_loader):\n",
        "                if i >= 100:  # Profile on 100 batches\n",
        "                    break\n",
        "                outputs = model(inputs)\n",
        "\n",
        "    print(f\"Profiling results for {activation_function}:\")\n",
        "    print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
        "    print(\"\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yf5hoUqjEVUw",
        "outputId": "e6f94cd4-6407-4ecc-a5d2-43a4f3416bc0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Profiling results for ReLU:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        49.91%     193.445ms        64.93%     251.687ms       2.492ms      12.67 Mb           0 b           101  \n",
            "                                           aten::linear         0.53%       2.073ms        29.73%     115.249ms     288.123us      22.36 Mb      42.00 Kb           400  \n",
            "                                            aten::addmm        26.85%     104.061ms        28.38%     109.989ms     274.973us      22.36 Mb      22.36 Mb           400  \n",
            "                                           aten::select         8.45%      32.767ms         8.58%      33.262ms       2.573us           0 b           0 b         12928  \n",
            "                                            aten::stack         2.80%      10.843ms         6.44%      24.980ms     123.663us      12.67 Mb           0 b           202  \n",
            "                                       aten::batch_norm         0.20%     772.000us         3.79%      14.691ms      48.970us      21.88 Mb    -480.00 Kb           300  \n",
            "                           aten::_batch_norm_impl_index         0.65%       2.504ms         3.53%      13.701ms      45.670us      21.88 Mb     539.50 Kb           300  \n",
            "                                aten::native_batch_norm         2.29%       8.874ms         2.81%      10.884ms      36.280us      21.88 Mb    -682.00 Kb           300  \n",
            "                                        aten::unsqueeze         1.98%       7.676ms         2.00%       7.738ms       1.197us           0 b           0 b          6464  \n",
            "                                              aten::cat         1.60%       6.192ms         1.60%       6.192ms      30.653us      12.67 Mb      12.67 Mb           202  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 387.604ms\n",
            "\n",
            "\n",
            "\n",
            "Profiling results for Tanh:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        45.27%     282.822ms        61.96%     387.110ms       3.833ms      12.67 Mb           0 b           101  \n",
            "                                           aten::linear         0.46%       2.863ms        28.65%     179.037ms     447.592us      22.36 Mb           0 b           400  \n",
            "                                            aten::addmm        26.17%     163.506ms        27.35%     170.866ms     427.165us      22.36 Mb      22.36 Mb           400  \n",
            "                                           aten::select         8.55%      53.441ms         8.80%      54.990ms       4.254us           0 b           0 b         12928  \n",
            "                                            aten::stack         3.42%      21.345ms         7.89%      49.298ms     244.050us      12.67 Mb           0 b           202  \n",
            "                                             aten::tanh         5.61%      35.067ms         5.61%      35.067ms     116.890us      21.88 Mb      21.88 Mb           300  \n",
            "                                       aten::batch_norm         0.21%       1.333ms         3.77%      23.543ms      78.477us      21.88 Mb    -128.00 Kb           300  \n",
            "                           aten::_batch_norm_impl_index         0.54%       3.361ms         3.54%      22.135ms      73.783us      21.88 Mb     128.00 Kb           300  \n",
            "                                aten::native_batch_norm         2.33%      14.566ms         2.86%      17.887ms      59.623us      21.88 Mb    -715.00 Kb           300  \n",
            "                                        aten::unsqueeze         2.23%      13.947ms         2.29%      14.332ms       2.217us           0 b           0 b          6464  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 624.811ms\n",
            "\n",
            "\n",
            "\n",
            "Profiling results for Sigmoid:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           aten::linear         0.80%       1.963ms        45.84%     112.542ms     281.355us      22.36 Mb      42.00 Kb           400  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        22.40%      54.989ms        44.97%     110.422ms       1.093ms      12.67 Mb           0 b           101  \n",
            "                                            aten::addmm        41.64%     102.234ms        43.82%     107.582ms     268.955us      22.36 Mb      22.36 Mb           400  \n",
            "                                           aten::select        12.80%      31.423ms        12.90%      31.672ms       2.450us           0 b           0 b         12928  \n",
            "                                            aten::stack         4.18%      10.262ms         9.68%      23.761ms     117.629us      12.67 Mb           0 b           202  \n",
            "                                       aten::batch_norm         0.28%     694.000us         5.66%      13.908ms      46.360us      21.88 Mb    -416.00 Kb           300  \n",
            "                           aten::_batch_norm_impl_index         0.98%       2.399ms         5.31%      13.032ms      43.440us      21.88 Mb     479.50 Kb           300  \n",
            "                                aten::native_batch_norm         3.38%       8.293ms         4.15%      10.201ms      34.003us      21.88 Mb      -1.01 Mb           300  \n",
            "                                          aten::sigmoid         3.43%       8.418ms         3.43%       8.418ms      28.060us      21.88 Mb      21.88 Mb           300  \n",
            "                                        aten::unsqueeze         2.94%       7.214ms         2.97%       7.296ms       1.129us           0 b           0 b          6464  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 245.531ms\n",
            "\n",
            "\n",
            "\n",
            "Profiling results for GeLU:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                           aten::linear         0.61%       1.840ms        37.01%     111.139ms     277.848us      22.36 Mb      10.00 Kb           400  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        18.40%      55.252ms        36.93%     110.895ms       1.098ms      12.67 Mb           0 b           101  \n",
            "                                            aten::addmm        33.45%     100.462ms        35.36%     106.201ms     265.502us      22.36 Mb      22.36 Mb           400  \n",
            "                                             aten::gelu        21.08%      63.292ms        21.08%      63.292ms     210.973us      21.88 Mb      21.88 Mb           300  \n",
            "                                           aten::select        10.55%      31.675ms        10.65%      31.983ms       2.474us           0 b           0 b         12928  \n",
            "                                            aten::stack         3.41%      10.235ms         7.88%      23.660ms     117.129us      12.67 Mb           0 b           202  \n",
            "                                       aten::batch_norm         0.21%     636.000us         4.91%      14.749ms      49.163us      21.88 Mb    -416.00 Kb           300  \n",
            "                           aten::_batch_norm_impl_index         1.07%       3.222ms         4.62%      13.878ms      46.260us      21.88 Mb     603.50 Kb           300  \n",
            "                                aten::native_batch_norm         2.81%       8.451ms         3.48%      10.445ms      34.817us      21.88 Mb    -831.00 Kb           300  \n",
            "                                        aten::unsqueeze         2.38%       7.153ms         2.40%       7.215ms       1.116us           0 b           0 b          6464  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 300.304ms\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetworkBatchNorm(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(NeuralNetworkBatchNorm, self).__init__()\n",
        "        self.layer1 = nn.Sequential(nn.Linear(input_size, 512), nn.BatchNorm1d(512), nn.ReLU())\n",
        "        self.layer2 = nn.Sequential(nn.Linear(512, 256), nn.BatchNorm1d(256), nn.ReLU())\n",
        "        self.layer3 = nn.Sequential(nn.Linear(256, 128), nn.BatchNorm1d(128), nn.ReLU())\n",
        "        self.output_layer = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        return self.output_layer(x)\n",
        "\n",
        "class NeuralNetworkDropout(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(NeuralNetworkDropout, self).__init__()\n",
        "        self.layer1 = nn.Sequential(nn.Linear(input_size, 512), nn.Dropout(0.5), nn.ReLU())\n",
        "        self.layer2 = nn.Sequential(nn.Linear(512, 256), nn.Dropout(0.5), nn.ReLU())\n",
        "        self.layer3 = nn.Sequential(nn.Linear(256, 128), nn.Dropout(0.5), nn.ReLU())\n",
        "        self.output_layer = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        return self.output_layer(x)\n"
      ],
      "metadata": {
        "id": "wGtmZdrKGXjS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"BatchNorm\": NeuralNetworkBatchNorm(input_size, num_classes),\n",
        "    \"Dropout\": NeuralNetworkDropout(input_size, num_classes)\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    with profiler.profile(record_shapes=True, profile_memory=True, use_cuda=torch.cuda.is_available()) as prof:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, (inputs, _) in enumerate(test_loader):\n",
        "                if i >= 100:\n",
        "                    break\n",
        "                outputs = model(inputs)\n",
        "\n",
        "    print(f\"Profiling results for {name}:\")\n",
        "    print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
      ],
      "metadata": {
        "id": "nB_tJqXWHDmT",
        "outputId": "55bf0e1d-81e5-4df0-8fda-4e0efbb56699",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Profiling results for BatchNorm:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        57.06%     243.266ms        70.63%     301.127ms       2.981ms      12.67 Mb           0 b           101  \n",
            "                                           aten::linear         0.45%       1.931ms        24.81%     105.772ms     264.430us      22.36 Mb      20.00 Kb           400  \n",
            "                                            aten::addmm        22.31%      95.110ms        23.63%     100.753ms     251.882us      22.36 Mb      22.36 Mb           400  \n",
            "                                           aten::select         7.78%      33.183ms         7.84%      33.428ms       2.586us           0 b           0 b         12928  \n",
            "                                            aten::stack         2.46%      10.470ms         5.73%      24.433ms     120.955us      12.67 Mb           0 b           202  \n",
            "                                       aten::batch_norm         0.13%     552.000us         3.33%      14.179ms      47.263us      21.88 Mb    -864.00 Kb           300  \n",
            "                           aten::_batch_norm_impl_index         0.57%       2.449ms         3.11%      13.257ms      44.190us      21.88 Mb     924.50 Kb           300  \n",
            "                                aten::native_batch_norm         2.03%       8.657ms         2.52%      10.726ms      35.753us      21.88 Mb    -952.50 Kb           300  \n",
            "                                        aten::unsqueeze         1.80%       7.689ms         1.82%       7.758ms       1.200us           0 b           0 b          6464  \n",
            "                                              aten::cat         1.42%       6.057ms         1.42%       6.057ms      29.985us      12.67 Mb      12.67 Mb           202  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 426.334ms\n",
            "\n",
            "Profiling results for Dropout:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg       CPU Mem  Self CPU Mem    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "enumerate(DataLoader)#_SingleProcessDataLoaderIter._...        24.39%      88.651ms        50.78%     184.581ms       1.828ms      12.67 Mb           0 b           101  \n",
            "                                           aten::linear         0.84%       3.047ms        47.01%     170.877ms     427.192us      22.36 Mb       5.00 Kb           400  \n",
            "                                            aten::addmm        42.65%     155.027ms        44.62%     162.197ms     405.493us      22.36 Mb      22.36 Mb           400  \n",
            "                                           aten::select        14.90%      54.156ms        15.27%      55.496ms       4.293us           0 b           0 b         12928  \n",
            "                                            aten::stack         5.06%      18.379ms        11.12%      40.434ms     200.168us      12.67 Mb           0 b           202  \n",
            "                                        aten::unsqueeze         3.80%      13.813ms         3.88%      14.115ms       2.184us           0 b           0 b          6464  \n",
            "                                              aten::cat         2.10%       7.638ms         2.10%       7.638ms      37.812us      12.67 Mb      12.67 Mb           202  \n",
            "                                             aten::relu         0.39%       1.430ms         2.09%       7.601ms      25.337us      21.88 Mb      64.00 Kb           300  \n",
            "                                        aten::clamp_min         1.70%       6.189ms         1.70%       6.189ms      20.630us      21.88 Mb      21.88 Mb           300  \n",
            "                                                aten::t         0.67%       2.432ms         1.56%       5.674ms      14.185us           0 b           0 b           400  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 363.501ms\n",
            "\n"
          ]
        }
      ]
    }
  ]
}